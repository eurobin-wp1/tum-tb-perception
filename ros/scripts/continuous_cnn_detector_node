#!/usr/bin/env python3

"""
Runs a CNN detector continuously on every incoming image messages and publishes
the results.
Optionally runs the detector only after a ROS/UDP trigger message.
"""

import os
import sys
import time
import pickle
import datetime

import rospy
import rospkg
import cv2
import torch

from cv_bridge import CvBridge, CvBridgeError

from sensor_msgs.msg import Image
from eurobin_perception.msg import BoundingBox, BoundingBoxList

from eurobin_perception.image_detection import ImageDetector

supported_torch_devices_ = ['cpu', 'gpu']
triggered_ = False

## ----------------------------------------------------------------------
## ROS Callbacks and Message Initializations:
## ----------------------------------------------------------------------

current_image_msg_ = None

def image_callback(msg):
    global current_image_msg_
    current_image_msg_ = msg


if __name__ == '__main__':
    ## ----------------------------------------------------------------------
    ## ROS Initializations:
    ## ----------------------------------------------------------------------
    rospy.init_node('cnn_detector')
    rate = rospy.Rate(10)

    package_path = rospkg.RosPack().get_path('eurobin_perception')

    model_weights_file_path = rospy.get_param('~model_weights_file_path', '')
    class_colors_file_path = rospy.get_param('~class_colors_file_path','')
    dataset_dir_path = rospy.get_param('~dataset_dir_path', '')
    output_dir_path = rospy.get_param('~output_dir_path', 
                                      os.path.join(package_path, 'output_data'))
    confidence_threshold = rospy.get_param('~confidence_threshold', 0.7)
    run_on_trigger = rospy.get_param('~run_on_trigger', False)

    image_topic = rospy.get_param('~image_topic', '/camera/color/image_raw')
    image_pub_topic = rospy.get_param('~image_pub_topic', 
                                      '/eurobin_perception/detection_images')
    input_image_pub_topic = rospy.get_param('~input_image_pub_topic', 
                                            '/eurobin_perception/input_images')
    detection_pub_topic = rospy.get_param('~detection_pub_topic', 
                                          '/eurobin_perception/detection_result')

    image_subscriber = rospy.Subscriber(image_topic, Image, image_callback)

    publish_visual_output = rospy.get_param('~publish_visual_output', True)
    save_output = rospy.get_param('~save_output', False)

    device = rospy.get_param('~device', 'cpu')

    bb_publisher = rospy.Publisher(detection_pub_topic, BoundingBoxList, queue_size=10)
    if publish_visual_output:
        detection_image_publisher = rospy.Publisher(image_pub_topic, Image, queue_size=10)
        input_image_publisher = rospy.Publisher(input_image_pub_topic, Image, queue_size=10)

    # Verify device for detection model:
    if device in supported_torch_devices_:
        rospy.loginfo('[cnn_detector] Will run model on {}'.format(device))
    else:
        rospy.logerr('[cnn_detector] Invalid value for device parameter! Must be one of {}'.format(supported_torch_devices_))
        sys.exit(1)
    if device == 'gpu' and not torch.cuda.is_available():
        rospy.logerr('[cnn_detector] Could not detect gpu device! Terminating.')
        sys.exit(1)

    # Set up output data directory:
    if save_output:
        output_sub_dir_path = 'cnn_detector_output_' + \
                              datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir_path = os.path.join(output_dir_path, output_sub_dir_path)
        rospy.loginfo(f'[cnn_detector] Saving output data in ' + \
                      f'{output_dir_path}')

        if not os.path.isdir(output_dir_path):
            rospy.loginfo(f'[cnn_detector] Output directory does not exist! ' + \
                          f' Creating now...')
            os.makedirs(output_dir_path)

    bridge = CvBridge()

    ## ----------------------------------------------------------------------
    ## Detector Initialization:
    ## ----------------------------------------------------------------------

    rospy.loginfo('[cnn_detector] Initializing ImageDetector...')
    detector = ImageDetector(dataset_dir_path=dataset_dir_path, 
                             model_weights_file_path=model_weights_file_path, 
                             class_colors_file_path=class_colors_file_path, 
                             confidence_threshold=confidence_threshold,
                             device=device)

    ## ----------------------------------------------------------------------
    ## Detector Execution:
    ## ----------------------------------------------------------------------

    rospy.loginfo(f'[cnn_detector] Subscribing to image topic: {image_topic}')
    rospy.loginfo('[cnn_detector] Waiting for reception of first image message...')
    try:
        while current_image_msg_ is None:
            rospy.sleep(0.1)
    except (KeyboardInterrupt, rospy.ROSInterruptException):
        rospy.loginfo('[cnn_detector] Terminating...')
        sys.exit(0)

    rospy.loginfo('[cnn_detector] Received first image message')

    if not run_on_trigger:
        rospy.loginfo('[cnn_detector] Continuously running detection on ' + \
                      'incoming messages...')
    else:
        rospy.loginfo('[cnn_detector] Will run detection at every trigger ' + \
                      'on the latest message...')
    try:
        while not rospy.is_shutdown():
            try:
                rate.sleep()
            except rospy.ROSTimeMovedBackwardsException as e:
                rospy.logwarn('[cnn_detector] Caught ROSTimeMovedBackwardsException ' + \
                              'when executing rate.sleep(). This can happen when ' + \
                              'incoming messages had stopped, and have just ' + \
                              'resumed publishing.')

            if run_on_trigger:
                if not triggered_:
                    continue
                else:
                    rospy.loginfo('[cnn_detector] Received trigger message')

            rospy.loginfo('[cnn_detector] Running detection model on image...')
            detection_start_time = time.time()

            try:
                image_cv = bridge.imgmsg_to_cv2(current_image_msg_, "bgr8")
            except CvBridgeError as e:
                rospy.logwarn('[cnn_detector] Failed to convert image message to' + \
                              ' opencv format! Skipping...')
                print('Error:', e)
                continue

            detector_result = detector.detect_objects(
                    image_cv, 
                    return_annotated_image=publish_visual_output or \
                                           save_output
            )
            bboxes = detector_result[0]
            model_inference_time = detector_result[1]
            detection_image_cv = detector_result[2]
            rospy.loginfo(f'[cnn_detector] Model inference time: ' + \
                          f'{model_inference_time:.2f}s')

            # Publish results in a BoundingBoxList message:
            bbox_list_msg = BoundingBoxList()
            for bbox_dict in bboxes:
                bbox_msg = BoundingBox()
                bbox_msg.xmin = bbox_dict['xmin']
                bbox_msg.xmax = bbox_dict['xmax']
                bbox_msg.ymin = bbox_dict['ymin']
                bbox_msg.ymax = bbox_dict['ymax']
                bbox_msg.label = bbox_dict['class']
                bbox_msg.confidence = bbox_dict['confidence']

                bbox_list_msg.bounding_boxes.append(bbox_msg)

            bb_publisher.publish(bbox_list_msg)

            if publish_visual_output:
                input_image_msg = bridge.cv2_to_imgmsg(image_cv, encoding="bgr8")
                input_image_msg.header.stamp = rospy.Time.now()
                input_image_msg.header.frame_id = current_image_msg_.header.frame_id
                input_image_publisher.publish(input_image_msg)

                detection_image_msg = bridge.cv2_to_imgmsg(detection_image_cv, 
                                                           encoding="bgr8")
                detection_image_msg.header.stamp = rospy.Time.now()
                detection_image_msg.header.frame_id = current_image_msg_.header.frame_id
                detection_image_publisher.publish(detection_image_msg)

            detection_time = time.time() - detection_start_time
            rospy.loginfo(f'[cnn_detector] Finished in {detection_time:.2f}s')

            # Optionally save results: input image, annotated images, and detection
            # result (bboxes) in a pickle file.
            if save_output:
                detection_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                with open(os.path.join(output_dir_path, 
                                       f'detection_result_{detection_str}.pkl'), 
                          'wb') as handle:
                    pickle.dump(bboxes, handle, protocol=pickle.HIGHEST_PROTOCOL)
                cv2.imwrite(os.path.join(output_dir_path, 
                                         f'input_image_{detection_str}.png'), 
                            image_cv)
                cv2.imwrite(os.path.join(output_dir_path, 
                                         f'detection_image_{detection_str}.png'), 
                            detection_image_cv)

    except (KeyboardInterrupt, rospy.ROSInterruptException):
        rospy.loginfo('[cnn_detector] Stopping node')
