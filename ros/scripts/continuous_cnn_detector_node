#!/usr/bin/env python3

"""
Runs a CNN detector continuously on every incoming image messages and publishes
the results.
Optionally runs the detector only after a ROS/UDP trigger message.
"""

import os
import sys
import time
import json
import signal
import pickle
import socket
import datetime

import cv2
import rospy
import rospkg
import torch

from cv_bridge import CvBridge, CvBridgeError

from std_msgs.msg import Bool
from sensor_msgs.msg import Image
from eurobin_perception.msg import BoundingBox, BoundingBoxList

from eurobin_perception.image_detection import ImageDetector

supported_torch_devices_ = ['cpu', 'gpu']
triggered_ = False

## ----------------------------------------------------------------------
## UDP Parameters
## ----------------------------------------------------------------------

udp_buffer_size_ = 1024

## ----------------------------------------------------------------------
## ROS Callbacks and Message Initializations:
## ----------------------------------------------------------------------

current_image_msg_ = None

def image_callback(msg):
    global current_image_msg_
    current_image_msg_ = msg

def trigger_callback(msg):
    global triggered_

    rospy.loginfo('[cnn_detector] Received trigger ROS message')
    triggered_ = msg.data


if __name__ == '__main__':
    ## ----------------------------------------------------------------------
    ## ROS Initializations:
    ## ----------------------------------------------------------------------
    rospy.init_node('cnn_detector')
    rate = rospy.Rate(10)

    package_path = rospkg.RosPack().get_path('eurobin_perception')

    model_weights_file_path = rospy.get_param('~model_weights_file_path', '')
    class_colors_file_path = rospy.get_param('~class_colors_file_path','')
    dataset_dir_path = rospy.get_param('~dataset_dir_path', '')
    output_dir_path = rospy.get_param('~output_dir_path', 
                                      os.path.join(package_path, 'output_data'))
    confidence_threshold = rospy.get_param('~confidence_threshold', 0.7)
    run_on_trigger = rospy.get_param('~run_on_trigger', False)
    run_on_udp_trigger = rospy.get_param('~run_on_udp_trigger', True)
    udp_ip = rospy.get_param('~udp_ip', 'localhost')
    udp_port = rospy.get_param('~udp_port', 8000)

    image_topic = rospy.get_param('~image_topic', '/camera/color/image_raw')
    trigger_topic = rospy.get_param('~trigger_topic', 
                                    '/eurobin_perception/detector_trigger')
    image_pub_topic = rospy.get_param('~image_pub_topic', 
                                      '/eurobin_perception/detection_images')
    input_image_pub_topic = rospy.get_param('~input_image_pub_topic', 
                                            '/eurobin_perception/input_images')
    detection_pub_topic = rospy.get_param('~detection_pub_topic', 
                                          '/eurobin_perception/detection_result')

    image_subscriber = rospy.Subscriber(image_topic, Image, image_callback)
    if run_on_trigger:
        trigger_subscriber = rospy.Subscriber(trigger_topic, Bool, trigger_callback)

    publish_visual_output = rospy.get_param('~publish_visual_output', True)
    save_output = rospy.get_param('~save_output', False)

    device = rospy.get_param('~device', 'cpu')

    bb_publisher = rospy.Publisher(detection_pub_topic, BoundingBoxList, queue_size=10)
    if publish_visual_output:
        detection_image_publisher = rospy.Publisher(image_pub_topic, Image, queue_size=10)
        input_image_publisher = rospy.Publisher(input_image_pub_topic, Image, queue_size=10)

    # Verify device for detection model:
    if device in supported_torch_devices_:
        rospy.loginfo('[cnn_detector] Will run model on {}'.format(device))
    else:
        rospy.logerr('[cnn_detector] Invalid value for device parameter! Must be one of {}'.format(supported_torch_devices_))
        sys.exit(1)
    if device == 'gpu' and not torch.cuda.is_available():
        rospy.logerr('[cnn_detector] Could not detect gpu device! Terminating.')
        sys.exit(1)

    # Verify trigger setting (ROS OR UDP):
    if run_on_trigger and run_on_udp_trigger:
        rospy.logerr('[cnn_detector] Node supports trigger messages from' + \
                     ' either ROS or UDP, but run_on_trigger and' + \
                     ' run_on_udp_trigger were both set to true!')
        rospy.logerr('[cnn_detector] Terminating.')
        sys.exit(1)

    # Set up output data directory:
    if save_output:
        output_sub_dir_path = 'cnn_detector_output_' + \
                              datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir_path = os.path.join(output_dir_path, output_sub_dir_path)
        rospy.loginfo(f'[cnn_detector] Saving output data in ' + \
                      f'{output_dir_path}')

        if not os.path.isdir(output_dir_path):
            rospy.loginfo(f'[cnn_detector] Output directory does not exist! ' + \
                          f' Creating now...')
            os.makedirs(output_dir_path)

    bridge = CvBridge()

    ## ----------------------------------------------------------------------
    ## Detector Initialization:
    ## ----------------------------------------------------------------------

    rospy.loginfo('[cnn_detector] Initializing ImageDetector...')
    detector = ImageDetector(dataset_dir_path=dataset_dir_path, 
                             model_weights_file_path=model_weights_file_path, 
                             class_colors_file_path=class_colors_file_path, 
                             confidence_threshold=confidence_threshold,
                             device=device)

    ## ----------------------------------------------------------------------
    ## Detector Execution:
    ## ----------------------------------------------------------------------

    rospy.loginfo(f'[cnn_detector] Subscribing to image topic: {image_topic}')
    rospy.loginfo('[cnn_detector] Waiting for reception of first image message...')
    try:
        while current_image_msg_ is None:
            rospy.sleep(0.1)
    except (KeyboardInterrupt, rospy.ROSInterruptException):
        rospy.loginfo('[cnn_detector] Terminating...')
        sys.exit(0)

    rospy.loginfo('[cnn_detector] Received first image message')

    if run_on_trigger:
        rospy.loginfo(f'[cnn_detector] Will run detection on the latest '
                      f'image message at every trigger ROS message on ' + \
                      f'on topic {trigger_topic}...')
    elif run_on_udp_trigger:
        rospy.loginfo(f'[cnn_detector] Will run detection on the latest '
                      f'image message at every trigger UDP message on ' + \
                      f' over IP {udp_ip} and port {udp_port}...')

        udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        udp_socket.settimeout(None)
        udp_socket.bind((udp_ip, udp_port))
    else:
        rospy.loginfo('[cnn_detector] Continuously running detection on ' + \
                      'incoming image messages...')

    try:
        while not rospy.is_shutdown():
            if run_on_trigger:
                # Note: using a signal SIGINT handler here because a try-except
                # block does not work for the inner while loop (does not terminate cleanly).
                signal.signal(signal.SIGINT, signal.SIG_DFL);
                while not triggered_:
                    rate.sleep()
                triggered_ = False
            elif run_on_udp_trigger:
                # Note: the following will block until a message is received:
                signal.signal(signal.SIGINT, signal.SIG_DFL);
                udp_msg, udp_addr = udp_socket.recvfrom(udp_buffer_size_)

                rospy.loginfo('[cnn_detector] Received trigger UDP message')
                udp_msg_data = json.loads(udp_msg.decode())

                try:
                    if type(udp_msg_data["trigger"]).__name__ != 'bool' or \
                            udp_msg_data['trigger'] != True:
                        rospy.logwarn('[cnn_detector] Received invalid value' + \
                                      ' in UDP message dict for key trigger:' + \
                                     f' {udp_msg_data["trigger"]}. Will only' + \
                                      ' trigger on "True". Ignoring... ')
                        continue
                except Exception as e:
                    rospy.logwarn('[cnn_detector] Could not access trigger' + \
                                  ' information in UDP message! Please check' + \
                                 f' message format!. Ignoring...')
                    continue
            else:
                try:
                    rate.sleep()
                except rospy.ROSTimeMovedBackwardsException as e:
                    rospy.logwarn('[cnn_detector] Caught ROSTimeMovedBackwardsException ' + \
                                  'when executing rate.sleep(). This can happen when ' + \
                                  'incoming messages had stopped, and have just ' + \
                                  'resumed publishing.')

            rospy.loginfo('[cnn_detector] Running detection model on image...')
            detection_start_time = time.time()

            try:
                image_cv = bridge.imgmsg_to_cv2(current_image_msg_, "bgr8")
            except CvBridgeError as e:
                rospy.logwarn('[cnn_detector] Failed to convert image message to' + \
                              ' opencv format! Skipping...')
                print('Error:', e)
                continue

            detector_result = detector.detect_objects(
                    image_cv, 
                    return_annotated_image=publish_visual_output or \
                                           save_output
            )
            bboxes = detector_result[0]
            model_inference_time = detector_result[1]
            detection_image_cv = detector_result[2]
            rospy.loginfo(f'[cnn_detector] Model inference time: ' + \
                          f'{model_inference_time:.2f}s')

            # Publish results in a BoundingBoxList message:
            bbox_list_msg = BoundingBoxList()
            for bbox_dict in bboxes:
                bbox_msg = BoundingBox()
                bbox_msg.xmin = bbox_dict['xmin']
                bbox_msg.xmax = bbox_dict['xmax']
                bbox_msg.ymin = bbox_dict['ymin']
                bbox_msg.ymax = bbox_dict['ymax']
                bbox_msg.label = bbox_dict['class']
                bbox_msg.confidence = bbox_dict['confidence']

                bbox_list_msg.bounding_boxes.append(bbox_msg)

            bb_publisher.publish(bbox_list_msg)

            if publish_visual_output:
                input_image_msg = bridge.cv2_to_imgmsg(image_cv, encoding="bgr8")
                input_image_msg.header.stamp = rospy.Time.now()
                input_image_msg.header.frame_id = current_image_msg_.header.frame_id
                input_image_publisher.publish(input_image_msg)

                detection_image_msg = bridge.cv2_to_imgmsg(detection_image_cv, 
                                                           encoding="bgr8")
                detection_image_msg.header.stamp = rospy.Time.now()
                detection_image_msg.header.frame_id = current_image_msg_.header.frame_id
                detection_image_publisher.publish(detection_image_msg)

            detection_time = time.time() - detection_start_time
            rospy.loginfo(f'[cnn_detector] Finished in {detection_time:.2f}s')

            # Optionally save results: input image, annotated images, and detection
            # result (bboxes) in a pickle file.
            if save_output:
                detection_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                with open(os.path.join(output_dir_path, 
                                       f'detection_result_{detection_str}.pkl'), 
                          'wb') as handle:
                    pickle.dump(bboxes, handle, protocol=pickle.HIGHEST_PROTOCOL)
                cv2.imwrite(os.path.join(output_dir_path, 
                                         f'input_image_{detection_str}.png'), 
                            image_cv)
                cv2.imwrite(os.path.join(output_dir_path, 
                                         f'detection_image_{detection_str}.png'), 
                            detection_image_cv)

    except (KeyboardInterrupt, rospy.ROSInterruptException):
        rospy.loginfo('[cnn_detector] Stopping node')
